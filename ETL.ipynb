{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import sqlalchemy as sql\n",
    "from ftp2 import download, upload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Criei uma uma função simples para baixar os arquivos do FTP.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------------\n",
      "Conectando...\n",
      "O MICRODADOS_ENEM_2019.csv já existe no diretório.\n",
      "Digite 'S' para sobrescrever o arquivo existente: n\n",
      "Download não Concluído.\n",
      "O Tabelas Auxiliares.xlsx já existe no diretório.\n",
      "Digite 'S' para sobrescrever o arquivo existente: n\n"
     ]
    }
   ],
   "source": [
    "download(arquivo='MICRODADOS_ENEM_2019.csv',dir_nome='DADOS', ip='localhost', user=['leandric', 'teste123'], sobrescrever=False, verbose=True)\n",
    "download(arquivo='Tabelas Auxiliares.xlsx',dir_nome='ANALISE', ip='localhost', user=['leandric', 'teste123'], sobrescrever=False, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lista de colunas que usarei neste exemplo\n",
    "variaveis = ['SG_UF_RESIDENCIA'\n",
    ",'NU_IDADE'\n",
    ",'TP_SEXO'\n",
    ",'TP_COR_RACA'\n",
    ",'TP_ANO_CONCLUIU'\n",
    ",'TP_ESCOLA'\n",
    ",'IN_NOME_SOCIAL'\n",
    ",'NU_NOTA_CN'\n",
    ",'NU_NOTA_CH'\n",
    ",'NU_NOTA_LC'\n",
    ",'NU_NOTA_MT'\n",
    ",'TP_STATUS_REDACAO'\n",
    ",'NU_NOTA_REDACAO'\n",
    ",'TP_LINGUA'\n",
    ",'Q006'\n",
    ",'Q025'\n",
    ",'TP_PRESENCA_CN'\n",
    ",'TP_PRESENCA_CH'\n",
    ",'TP_PRESENCA_LC'\n",
    ",'TP_PRESENCA_MT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#carregando o dataframe apos ter baixado do FTP passando no parametro as colunas de interesse.\n",
    "\n",
    "df_microdados = pd.read_csv('input_FTP/MICRODADOS_ENEM_2019.csv',encoding='ISO-8859-1', usecols = variaveis, index_col=None, sep = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataframes Auxiliares (dimensões e afins)\n",
    "\n",
    "df_idade = pd.read_excel(open('input_FTP/Tabelas Auxiliares.xlsx', 'rb'), sheet_name='Idade', index_col=None)\n",
    "df_sexo = pd.read_excel(open('input_FTP/Tabelas Auxiliares.xlsx', 'rb'), sheet_name='Sexo', index_col=None)\n",
    "df_presente_natureza = pd.read_excel(open('input_FTP/Tabelas Auxiliares.xlsx', 'rb'), sheet_name='PRESENCA_NATUREZA', index_col=None)\n",
    "df_presente_humanas = pd.read_excel(open('input_FTP/Tabelas Auxiliares.xlsx', 'rb'), sheet_name='PRESENCA_HUMANAS', index_col=None)\n",
    "df_presente_linguagem = pd.read_excel(open('input_FTP/Tabelas Auxiliares.xlsx', 'rb'), sheet_name='PRESENCA_LINGUAGEM', index_col=None)\n",
    "df_presente_matematica = pd.read_excel(open('input_FTP/Tabelas Auxiliares.xlsx', 'rb'), sheet_name='PRESENCA_MATEMATICA', index_col=None)\n",
    "df_acesso_internet = pd.read_excel(open('input_FTP/Tabelas Auxiliares.xlsx', 'rb'), sheet_name='ACESSO_INTERNET', index_col=None)\n",
    "df_renda_familiar = pd.read_excel(open('input_FTP/Tabelas Auxiliares.xlsx', 'rb'), sheet_name='RENDA_FA', index_col=None)\n",
    "df_estado = pd.read_excel(open('input_FTP/Tabelas Auxiliares.xlsx', 'rb'), sheet_name='ESTADO', index_col=None)\n",
    "df_raça = pd.read_excel(open('input_FTP/Tabelas Auxiliares.xlsx', 'rb'), sheet_name='RAÇA', index_col=None)\n",
    "df_conclusão_medio = pd.read_excel(open('input_FTP/Tabelas Auxiliares.xlsx', 'rb'), sheet_name='CONCLUSAO_ENSINO_ANO', index_col=None)\n",
    "df_tipo_escola = pd.read_excel(open('input_FTP/Tabelas Auxiliares.xlsx', 'rb'), sheet_name='TIPO_ESCOLA', index_col=None)\n",
    "df_status_redacao = pd.read_excel(open('input_FTP/Tabelas Auxiliares.xlsx', 'rb'), sheet_name='REDAÇÃO', index_col=None)\n",
    "df_idioma_escolhido = pd.read_excel(open('input_FTP/Tabelas Auxiliares.xlsx', 'rb'), sheet_name='LINGUAGEM_ESCOLHIDA', index_col=None)\n",
    "df_nome_social = pd.read_excel(open('input_FTP/Tabelas Auxiliares.xlsx', 'rb'), sheet_name='Nome_Social', index_col=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Estrtura de dados</h1>\n",
    "<p>Estudando o dicionários de dados optei por criar uma serie de dataframes auxiliares para extrair as informações eliminando os codigos de respostas.</p>\n",
    "<p>Traduzindo em um DER teriamos o modelo abaixo:</p>\n",
    "<img src=\"IMG/DER.PNG\" alt=\"Girl in a jacket\">\n",
    "<p><i>Aproveitei o modelo gerado pelo <span style=\"color:orange\">PowerBI</span> já que pretendo construir um painel nele com estes dataframes.</i></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fato_dw = pd.merge(left= origem_pedidos, right= origem_produto, how='left', left_on='produto', right_on='id')\n",
    "\n",
    "#idade\n",
    "df_microdados = pd.merge(left = df_microdados, right = df_idade, on=\"NU_IDADE\")\n",
    "df_microdados = pd.merge(left = df_microdados, right = df_sexo, on=\"TP_SEXO\")\n",
    "df_microdados = pd.merge(left = df_microdados, right = df_raça, on=\"TP_COR_RACA\")\n",
    "df_microdados = pd.merge(left = df_microdados, right = df_conclusão_medio, on=\"TP_ANO_CONCLUIU\")\n",
    "df_microdados = pd.merge(left = df_microdados, right = df_tipo_escola, on=\"TP_ESCOLA\")\n",
    "df_microdados = pd.merge(left = df_microdados, right = df_status_redacao, on=\"TP_STATUS_REDACAO\")\n",
    "df_microdados = pd.merge(left = df_microdados, right = df_idioma_escolhido, on=\"TP_LINGUA\")\n",
    "df_microdados = pd.merge(left = df_microdados, right = df_presente_natureza, on=\"TP_PRESENCA_CN\")\n",
    "df_microdados = pd.merge(left = df_microdados, right = df_presente_humanas, on=\"TP_PRESENCA_CH\")\n",
    "df_microdados = pd.merge(left = df_microdados, right = df_presente_linguagem, on=\"TP_PRESENCA_LC\")\n",
    "df_microdados = pd.merge(left = df_microdados, right = df_presente_matematica, on=\"TP_PRESENCA_MT\")\n",
    "df_microdados = pd.merge(left = df_microdados, right = df_acesso_internet, on=\"Q025\")\n",
    "df_microdados = pd.merge(left = df_microdados, right = df_renda_familiar, on=\"Q006\")\n",
    "df_microdados = pd.merge(left = df_microdados, right = df_nome_social, on=\"IN_NOME_SOCIAL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtro=['SG_UF_RESIDENCIA'\n",
    ",'NU_IDADE'\n",
    ",'NU_NOTA_CN'\n",
    ",'NU_NOTA_CH'\n",
    ",'NU_NOTA_LC'\n",
    ",'NU_NOTA_MT'\n",
    ",'NU_NOTA_REDACAO'\n",
    ",'Tipo Fase'\n",
    ",'Intervalo Idade'\n",
    ",'Sexo'\n",
    ",'Raça Declarada'\n",
    ",'Conclusão Ensino Médio'\n",
    ",'Tipo Escola'\n",
    ",'Status da Redação'\n",
    ",'Idioma Escolhido'\n",
    ",'Presença Natureza'\n",
    ",'Presença Humanas'\n",
    ",'Presença Linguagem'\n",
    ",'Presença Matemática'\n",
    ",'Acesso a Internet'\n",
    ",'Renda Familiar'\n",
    ",'Nome Social']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_microdados = df_microdados[filtro]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_microdados = df_microdados.rename(columns={'SG_UF_RESIDENCIA': 'UF'\n",
    ",'NU_IDADE':'Idade'\n",
    ",'NU_NOTA_CN':'Nota Ciencias da Natureza'\n",
    ",'NU_NOTA_CH':'Nota Ciencias Humanas'\n",
    ",'NU_NOTA_LC':'Nota Linguagem e Código'\n",
    ",'NU_NOTA_MT':'Nota Matemática'\n",
    ",'NU_NOTA_REDACAO':'Nota Redação'\n",
    ",'Tipo Fase':'Grupo Idade'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Estrtura de dados</h1>\n",
    "<p>Ao Final o DW ficara asssim:</p>\n",
    "\n",
    "<img src=\"IMG/DW.PNG\" alt=\"Estrutura da Tabela DW\">\n",
    "<p> Depois de selecionar e limpar os dados desejados de seus códigos para a informação que defato precisamos ver, reduzimos o arquivo de 3.1GB para 894MB, <i>vale notar que não realizei nenhum tipo de agrupamento.</i></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_microdados.to_csv('Uploads/DW.csv', encoding='ISO-8859-1', index=False, sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conexao = sql.create_engine(\"mysql+mysqlconnector://leandric:12345@localhost:3306/enem_2019\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calcula o chunksize máximo\n",
    "def cs(df):\n",
    "    cs = 2097 // len(df.columns)\n",
    "    if cs > 1000:\n",
    "        return 1000\n",
    "    return cs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_microdados.to_sql(name='enem_2019', con=conexao, if_exists='replace', index=False, chunksize=cs(df_microdados))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gerando arquivo para Upload\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'arquivo' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-e342bb3f2a7c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mupload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdir_origem\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Uploads'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_microdados\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdir_nome\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'FTP'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mip\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'localhost'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muser\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'leandric'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'teste123'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Desktop\\ETL\\ftp2.py\u001b[0m in \u001b[0;36mupload\u001b[1;34m(dir_origem, df, dir_nome, ip, user)\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Gerando arquivo para Upload\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Uploads/DW.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ISO-8859-1'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\";\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Enviadndo '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marquivo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m     \u001b[0mcx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFTP\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mip\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[0mcx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0muser\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'arquivo' is not defined"
     ]
    }
   ],
   "source": [
    "upload(dir_origem='Uploads', df = df_microdados, dir_nome='FTP', ip='localhost', user=['leandric','teste123'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
